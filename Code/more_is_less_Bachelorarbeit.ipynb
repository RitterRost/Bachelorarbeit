{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6350,"status":"ok","timestamp":1648127065603,"user":{"displayName":"Ritter Rost","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08820756572124446994"},"user_tz":-60},"id":"7ZmwTMWx9AcY"},"outputs":[],"source":["#imports \n","\n","%tensorflow_version 2.x\n","import tensorflow as tf \n","from tensorflow import keras \n","\n","#Help-liberies \n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":413,"status":"ok","timestamp":1648127066012,"user":{"displayName":"Ritter Rost","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08820756572124446994"},"user_tz":-60},"id":"pwiYmWF29Kh2"},"outputs":[],"source":["#The function takes the train labels and the amount of noise we want to apply \n","#The return value is the train_labels with noise \n","import random\n","\n","def adding_noise(labels, percent):\n","  labels_with_noise = np.zeros((len(labels)))\n","  for i in range(len(labels)):\n","    r = random.random()\n","    if r < percent:\n","      labels_with_noise[i] = int(labels[i] + 1+ 9*random.random())%10\n","    else:\n","      labels_with_noise[i] = labels[i] \n","  return labels_with_noise"]},{"cell_type":"markdown","metadata":{"id":"0CR7pt0n-IKt"},"source":["Creating the Class Model, where modelscan be created, trained and observed\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1648127066244,"user":{"displayName":"Ritter Rost","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08820756572124446994"},"user_tz":-60},"id":"6xq2wEh697S-"},"outputs":[],"source":["\n","\n","class Model:\n","      model = keras.Sequential()\n","\n","      def __init__(self, layers, layersize):\n","\n","        self.layers = layers\n","        self.layersize = layersize\n","        #initializing the model\n","        self.model = keras.Sequential()\n","        self.model.add(keras.layers.Flatten(input_shape=(28,28)))#input layer\n","        for j in range(0, layers):\n","          self.model.add(keras.layers.Dense(layersize, activation=\"relu\")) #hidden layers\n","        self.model.add(keras.layers.Dense(10,activation='softmax')) #output layer\n","        #compile model\n","        self.model.compile(optimizer= 'adam' , \n","                           loss= 'sparse_categorical_crossentropy',metrics=['accuracy'])  \n","        self.model.count_params()\n","\n","      '''\n","      trains the model and returns a List of various data\n","      data[0] = the train loss after fitting the data \n","      data[1] = the train accuracy after fitting the data  \n","      data[2] = the test loss after evaluating the model \n","      data[3] = the test accuracy after evaluating the model  \n","      '''\n","\n","      def train(self,epoch,datasize,train_images,train_labels,test_images, test_labels):\n","        data = np.zeros(4)\n","        print(datasize,epoch)\n","\n","        #trainig the model until a certain accuracy is reached\n","        runs = 0\n","        train_loss = 100\n","        train_acc = 0\n","        e_per_run = 5\n","        for i in range(epoch):\n","          history = self.model.fit(train_images[:datasize], train_labels[:datasize],epochs = e_per_run)\n","          train_loss_all, train_acc_all = history.history.values()\n","          train_loss = train_loss_all[e_per_run-1]\n","          train_acc = train_acc_all[e_per_run-1]\n","          runs = runs + e_per_run\n","          if train_loss < 0.001:\n","            break\n","\n","        test_loss, test_acc = self.model.evaluate(test_images, test_labels, verbose=1)\n","        data[0] = train_loss\n","        data[1] = train_acc\n","        data[2] = test_loss\n","        data[3] = test_acc\n","        print(self.model.summary())\n","        return data\n","\n","      def getParameter(self):\n","        return self.model.count_params()\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":302,"status":"ok","timestamp":1648127069228,"user":{"displayName":"Ritter Rost","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08820756572124446994"},"user_tz":-60},"id":"nIA3dy4h-uOM"},"outputs":[],"source":["def trainModel(amount,min_layersize,max_layersize, layers, epochs, datasize, noise):\n","  a = max_layersize - min_layersize \n","  data = np.zeros((5,a))\n","\n","  #load dataset MNIST\n","  mnist = keras.datasets.mnist\n","  #spliting into testing and training\n","  (train_images, train_labels_without_noise), (test_images, test_labels) = mnist.load_data()\n","  #normalizing data\n","  train_images = train_images/255.0\n","  test_images = test_images/255.0\n","  #adding noise\n","  train_labels = adding_noise(train_labels_without_noise, noise)\n","\n","  \n","  '''\n","  data[0][i] = the train loss after fitting the data in iterration i (with i layers) \n","  data[1][i] = the train accuracy after fitting the data in iterration i (with i layers)  \n","  data[2][i] = the test loss after evaluating the model in iterration i (with i layers) \n","  data[3][i] = the test accuracy after evaluating the model in iterration i (with i layers) \n","  data[4][i] = the parameters of the model in iterration i (with i layers)\n","  '''\n","\n","  for i in range(0,max_layersize - min_layersize):\n","    data_help = [0,0,0,0,0]\n","    for j in range(0,amount):\n","      print(\"I an currently in run \",i, \" ===> The model has \", i+ min_layersize ,\"neurons. \")\n","      print(\"amount =\", amount) \n","      myModel = Model(layers,i + min_layersize)\n","      history = myModel.train(epochs, datasize,train_images,train_labels,test_images, test_labels)\n","      param   = myModel.getParameter()\n","      data_help[0] = data_help[0] + history[0] \n","      data_help[1] = data_help[1] + history[1]\n","      data_help[2] = data_help[2] + history[2]\n","      data_help[3] = data_help[3] + history[3]\n","      data_help[4] = data_help[4] + param\n","\n","    #maby filtering runs, that went wrong\n","    data[0][i] = data_help[0]/amount\n","    data[1][i] = data_help[1]/amount\n","    data[2][i] = data_help[2]/amount\n","    data[3][i] = data_help[3]/amount\n","    data[4][i] = data_help[4]\n","  return data "]},{"cell_type":"markdown","metadata":{"id":"UTPtKBXn-i_U"},"source":["in the next block, i want to creata a example curve of the double descent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NN4ivVmq-ig-"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"p7S5NL0X8RQR","outputId":"6e5f816b-eda9-48ee-d530-eddde961ad18","executionInfo":{"status":"ok","timestamp":1648152924107,"user_tz":-60,"elapsed":25778598,"user":{"displayName":"Ritter Rost","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08820756572124446994"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mDie letzten 5000Â Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9936\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9988\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.6827e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.1242e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2630 - accuracy: 0.9511\n","Model: \"sequential_267\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_266 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_532 (Dense)           (None, 54)                42390     \n","                                                                 \n"," dense_533 (Dense)           (None, 10)                550       \n","                                                                 \n","=================================================================\n","Total params: 42,940\n","Trainable params: 42,940\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  53  ===> The model has  54 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5908 - accuracy: 0.8396\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2931 - accuracy: 0.9193\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2361 - accuracy: 0.9337\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.9452\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1645 - accuracy: 0.9524\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1432 - accuracy: 0.9588\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.1224 - accuracy: 0.9664\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1040 - accuracy: 0.9718\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9752\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0801 - accuracy: 0.9800\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9822\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0617 - accuracy: 0.9846\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0527 - accuracy: 0.9880\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0459 - accuracy: 0.9893\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0391 - accuracy: 0.9921\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0345 - accuracy: 0.9935\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9948\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9959\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0209 - accuracy: 0.9973\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9981\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9978\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9988\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9995\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9998\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9997\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9991\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0086 - accuracy: 0.9979\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9949\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.9768e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2696 - accuracy: 0.9494\n","Model: \"sequential_268\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_267 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_534 (Dense)           (None, 54)                42390     \n","                                                                 \n"," dense_535 (Dense)           (None, 10)                550       \n","                                                                 \n","=================================================================\n","Total params: 42,940\n","Trainable params: 42,940\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  54  ===> The model has  55 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.6473 - accuracy: 0.8212\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2938 - accuracy: 0.9179\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2324 - accuracy: 0.9353\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1912 - accuracy: 0.9456\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1638 - accuracy: 0.9550\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1389 - accuracy: 0.9601\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.9676\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9693\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0909 - accuracy: 0.9744\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0814 - accuracy: 0.9786\n","Epoch 1/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0729 - accuracy: 0.9817\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9830\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9871\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0449 - accuracy: 0.9901\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9907\n","Epoch 1/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0350 - accuracy: 0.9935\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9937\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0247 - accuracy: 0.9962\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9963\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0192 - accuracy: 0.9976\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9983\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9992\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9994\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9989\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9987\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9995\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9958\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9977\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9993\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.5045e-04 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.4726e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 3ms/step - loss: 8.5269e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.5493e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.5076e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2730 - accuracy: 0.9510\n","Model: \"sequential_269\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_268 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_536 (Dense)           (None, 55)                43175     \n","                                                                 \n"," dense_537 (Dense)           (None, 10)                560       \n","                                                                 \n","=================================================================\n","Total params: 43,735\n","Trainable params: 43,735\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  54  ===> The model has  55 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6235 - accuracy: 0.8331\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2883 - accuracy: 0.9224\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2329 - accuracy: 0.9348\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.9464\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1583 - accuracy: 0.9559\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.9631\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1156 - accuracy: 0.9691\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9738\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0859 - accuracy: 0.9768\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0739 - accuracy: 0.9813\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0641 - accuracy: 0.9837\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0553 - accuracy: 0.9867\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0488 - accuracy: 0.9885\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9909\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9925\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9947\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9963\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0232 - accuracy: 0.9966\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9976\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9982\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9987\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9978\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9985\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9993\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9990\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9972\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.7879e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.4495e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2437 - accuracy: 0.9522\n","Model: \"sequential_270\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_269 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_538 (Dense)           (None, 55)                43175     \n","                                                                 \n"," dense_539 (Dense)           (None, 10)                560       \n","                                                                 \n","=================================================================\n","Total params: 43,735\n","Trainable params: 43,735\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  55  ===> The model has  56 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6519 - accuracy: 0.8264\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2879 - accuracy: 0.9222\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2289 - accuracy: 0.9362\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1930 - accuracy: 0.9460\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1632 - accuracy: 0.9526\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1408 - accuracy: 0.9611\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1176 - accuracy: 0.9666\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1057 - accuracy: 0.9687\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0921 - accuracy: 0.9742\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0781 - accuracy: 0.9789\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9831\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9844\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0507 - accuracy: 0.9885\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0438 - accuracy: 0.9909\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9917\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0327 - accuracy: 0.9934\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9955\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9956\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9968\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0185 - accuracy: 0.9974\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0155 - accuracy: 0.9982\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9994\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9988\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9993\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9995\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9990\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0065 - accuracy: 0.9994\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9997\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9954\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9987\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.4071e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.9519\n","Model: \"sequential_271\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_270 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_540 (Dense)           (None, 56)                43960     \n","                                                                 \n"," dense_541 (Dense)           (None, 10)                570       \n","                                                                 \n","=================================================================\n","Total params: 44,530\n","Trainable params: 44,530\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  55  ===> The model has  56 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6017 - accuracy: 0.8406\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.9238\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2185 - accuracy: 0.9388\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1809 - accuracy: 0.9485\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1505 - accuracy: 0.9569\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.9640\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1124 - accuracy: 0.9684\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9724\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0845 - accuracy: 0.9779\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0758 - accuracy: 0.9815\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0652 - accuracy: 0.9835\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9851\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9890\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0443 - accuracy: 0.9900\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9926\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0331 - accuracy: 0.9932\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9938\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9964\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9966\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9973\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9976\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9991\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9988\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0114 - accuracy: 0.9988\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9995\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9996\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9993\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9991\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9926\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9995\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.4242e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 3ms/step - loss: 8.1257e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.3207e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.6924e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2667 - accuracy: 0.9512\n","Model: \"sequential_272\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_271 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_542 (Dense)           (None, 56)                43960     \n","                                                                 \n"," dense_543 (Dense)           (None, 10)                570       \n","                                                                 \n","=================================================================\n","Total params: 44,530\n","Trainable params: 44,530\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  56  ===> The model has  57 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6093 - accuracy: 0.8324\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2803 - accuracy: 0.9192\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2186 - accuracy: 0.9347\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1776 - accuracy: 0.9511\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9574\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1245 - accuracy: 0.9650\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1058 - accuracy: 0.9726\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9763\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0786 - accuracy: 0.9807\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9831\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9845\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0502 - accuracy: 0.9885\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9903\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9925\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0325 - accuracy: 0.9935\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9958\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9959\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9964\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9978\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9980\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0121 - accuracy: 0.9991\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9993\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9993\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9991\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9919\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9987\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.9571e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.7613e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2408 - accuracy: 0.9528\n","Model: \"sequential_273\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_272 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_544 (Dense)           (None, 57)                44745     \n","                                                                 \n"," dense_545 (Dense)           (None, 10)                580       \n","                                                                 \n","=================================================================\n","Total params: 45,325\n","Trainable params: 45,325\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  56  ===> The model has  57 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6256 - accuracy: 0.8359\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2825 - accuracy: 0.9251\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2233 - accuracy: 0.9401\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1836 - accuracy: 0.9497\n","Epoch 5/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.1554 - accuracy: 0.9570\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1332 - accuracy: 0.9624\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1123 - accuracy: 0.9698\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0964 - accuracy: 0.9738\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0848 - accuracy: 0.9775\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0740 - accuracy: 0.9812\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0631 - accuracy: 0.9837\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0563 - accuracy: 0.9857\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0486 - accuracy: 0.9871\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9899\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9922\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0319 - accuracy: 0.9935\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9945\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9957\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0197 - accuracy: 0.9974\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9972\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0139 - accuracy: 0.9988\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0125 - accuracy: 0.9987\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9993\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9992\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9997\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9996\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9961\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9970\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 8.7987e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2481 - accuracy: 0.9515\n","Model: \"sequential_274\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_273 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_546 (Dense)           (None, 57)                44745     \n","                                                                 \n"," dense_547 (Dense)           (None, 10)                580       \n","                                                                 \n","=================================================================\n","Total params: 45,325\n","Trainable params: 45,325\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  57  ===> The model has  58 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6069 - accuracy: 0.8391\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2832 - accuracy: 0.9231\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2240 - accuracy: 0.9376\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1840 - accuracy: 0.9472\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1514 - accuracy: 0.9562\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1292 - accuracy: 0.9630\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1116 - accuracy: 0.9695\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0961 - accuracy: 0.9738\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0859 - accuracy: 0.9766\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0728 - accuracy: 0.9817\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9850\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9880\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9893\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9905\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9936\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9945\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9955\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0215 - accuracy: 0.9969\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9980\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0171 - accuracy: 0.9974\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9985\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9988\n","Epoch 3/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0124 - accuracy: 0.9984\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0095 - accuracy: 0.9996\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9994\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9996\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9938\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9994\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.9846e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.1335e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2529 - accuracy: 0.9512\n","Model: \"sequential_275\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_274 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_548 (Dense)           (None, 58)                45530     \n","                                                                 \n"," dense_549 (Dense)           (None, 10)                590       \n","                                                                 \n","=================================================================\n","Total params: 46,120\n","Trainable params: 46,120\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  57  ===> The model has  58 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5964 - accuracy: 0.8396\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2846 - accuracy: 0.9190\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2186 - accuracy: 0.9406\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1817 - accuracy: 0.9500\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1510 - accuracy: 0.9594\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1293 - accuracy: 0.9629\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1080 - accuracy: 0.9698\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9752\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9787\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9825\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0585 - accuracy: 0.9855\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0483 - accuracy: 0.9891\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0404 - accuracy: 0.9911\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9917\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9953\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9949\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0215 - accuracy: 0.9964\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9979\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0160 - accuracy: 0.9982\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9990\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9996\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9997\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9995\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9992\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9967\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.4899e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9910\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9995\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.2966e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.3029e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 5.5853e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2513 - accuracy: 0.9549\n","Model: \"sequential_276\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_275 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_550 (Dense)           (None, 58)                45530     \n","                                                                 \n"," dense_551 (Dense)           (None, 10)                590       \n","                                                                 \n","=================================================================\n","Total params: 46,120\n","Trainable params: 46,120\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  58  ===> The model has  59 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6135 - accuracy: 0.8333\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2841 - accuracy: 0.9198\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2173 - accuracy: 0.9415\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1802 - accuracy: 0.9471\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1488 - accuracy: 0.9579\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1270 - accuracy: 0.9623\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1084 - accuracy: 0.9712\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0921 - accuracy: 0.9748\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9783\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0689 - accuracy: 0.9821\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0606 - accuracy: 0.9847\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0512 - accuracy: 0.9890\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9900\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9927\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0341 - accuracy: 0.9929\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0262 - accuracy: 0.9956\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9960\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9971\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0160 - accuracy: 0.9982\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9991\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0122 - accuracy: 0.9990\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9998\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9987\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9943\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9965\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9997\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.9291e-04 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.7949e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.0239e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 5.5354e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 4.9778e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2701 - accuracy: 0.9497\n","Model: \"sequential_277\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_276 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_552 (Dense)           (None, 59)                46315     \n","                                                                 \n"," dense_553 (Dense)           (None, 10)                600       \n","                                                                 \n","=================================================================\n","Total params: 46,915\n","Trainable params: 46,915\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  58  ===> The model has  59 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.6256 - accuracy: 0.8299\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2894 - accuracy: 0.9189\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2298 - accuracy: 0.9352\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1914 - accuracy: 0.9465\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1630 - accuracy: 0.9533\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1390 - accuracy: 0.9600\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1201 - accuracy: 0.9662\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9721\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0903 - accuracy: 0.9752\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0772 - accuracy: 0.9795\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.9821\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0596 - accuracy: 0.9854\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0514 - accuracy: 0.9877\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9909\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9901\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0315 - accuracy: 0.9936\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0287 - accuracy: 0.9946\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9962\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9958\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9978\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9980\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9982\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9987\n","Epoch 4/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0102 - accuracy: 0.9990\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9996\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9996\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9993\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9978\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9994\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9918\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9993\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.4034e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.6319e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.7663e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2764 - accuracy: 0.9503\n","Model: \"sequential_278\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_277 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_554 (Dense)           (None, 59)                46315     \n","                                                                 \n"," dense_555 (Dense)           (None, 10)                600       \n","                                                                 \n","=================================================================\n","Total params: 46,915\n","Trainable params: 46,915\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  59  ===> The model has  60 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6078 - accuracy: 0.8380\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2846 - accuracy: 0.9196\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2259 - accuracy: 0.9381\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1862 - accuracy: 0.9483\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9567\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9618\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1121 - accuracy: 0.9677\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0979 - accuracy: 0.9745\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9784\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9829\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9855\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9866\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0462 - accuracy: 0.9884\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0389 - accuracy: 0.9920\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0322 - accuracy: 0.9943\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9950\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0237 - accuracy: 0.9964\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0192 - accuracy: 0.9976\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9985\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9988\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9990\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9994\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9994\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9993\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9996\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 0.9994\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9964\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9981\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.7965e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.8664e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.9667e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.0097e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2409 - accuracy: 0.9515\n","Model: \"sequential_279\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_278 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_556 (Dense)           (None, 60)                47100     \n","                                                                 \n"," dense_557 (Dense)           (None, 10)                610       \n","                                                                 \n","=================================================================\n","Total params: 47,710\n","Trainable params: 47,710\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  59  ===> The model has  60 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6201 - accuracy: 0.8346\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2691 - accuracy: 0.9267\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9417\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1710 - accuracy: 0.9506\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1410 - accuracy: 0.9605\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1177 - accuracy: 0.9656\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9745\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9775\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0722 - accuracy: 0.9815\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0629 - accuracy: 0.9840\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0543 - accuracy: 0.9871\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0459 - accuracy: 0.9889\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9928\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0318 - accuracy: 0.9951\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9948\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0248 - accuracy: 0.9959\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9977\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9979\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.9993\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9991\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9992\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9996\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9952\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9965\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.7570e-04 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.8165e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.8849e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.1633e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.5620e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2384 - accuracy: 0.9531\n","Model: \"sequential_280\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_279 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_558 (Dense)           (None, 60)                47100     \n","                                                                 \n"," dense_559 (Dense)           (None, 10)                610       \n","                                                                 \n","=================================================================\n","Total params: 47,710\n","Trainable params: 47,710\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  60  ===> The model has  61 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5920 - accuracy: 0.8415\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2763 - accuracy: 0.9232\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2179 - accuracy: 0.9399\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1824 - accuracy: 0.9487\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.9574\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1304 - accuracy: 0.9657\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1128 - accuracy: 0.9687\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0959 - accuracy: 0.9757\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0836 - accuracy: 0.9769\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9820\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0620 - accuracy: 0.9842\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0535 - accuracy: 0.9875\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9906\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0397 - accuracy: 0.9907\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9931\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9956\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9948\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0210 - accuracy: 0.9967\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9965\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9986\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9986\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9990\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9994\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9994\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9995\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9986\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 0.9997\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9996\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.6863e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.7968e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.6850e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.0920e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2506 - accuracy: 0.9497\n","Model: \"sequential_281\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_280 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_560 (Dense)           (None, 61)                47885     \n","                                                                 \n"," dense_561 (Dense)           (None, 10)                620       \n","                                                                 \n","=================================================================\n","Total params: 48,505\n","Trainable params: 48,505\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  60  ===> The model has  61 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6019 - accuracy: 0.8413\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2814 - accuracy: 0.9205\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2215 - accuracy: 0.9376\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1849 - accuracy: 0.9471\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1531 - accuracy: 0.9570\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1308 - accuracy: 0.9639\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1135 - accuracy: 0.9675\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0946 - accuracy: 0.9763\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9775\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9812\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0605 - accuracy: 0.9859\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0510 - accuracy: 0.9883\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0457 - accuracy: 0.9901\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9929\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9934\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9959\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9959\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9976\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9972\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9983\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9976\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9993\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9993\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9992\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9990\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9986\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0147 - accuracy: 0.9960\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9995\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.3018e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.3378e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.6395e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2618 - accuracy: 0.9524\n","Model: \"sequential_282\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_281 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_562 (Dense)           (None, 61)                47885     \n","                                                                 \n"," dense_563 (Dense)           (None, 10)                620       \n","                                                                 \n","=================================================================\n","Total params: 48,505\n","Trainable params: 48,505\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  61  ===> The model has  62 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5968 - accuracy: 0.8422\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2773 - accuracy: 0.9250\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2181 - accuracy: 0.9381\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1815 - accuracy: 0.9491\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9554\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1302 - accuracy: 0.9640\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1100 - accuracy: 0.9710\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0966 - accuracy: 0.9725\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0796 - accuracy: 0.9797\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.9823\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9867\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0522 - accuracy: 0.9870\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9908\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0365 - accuracy: 0.9931\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9944\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9951\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9964\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0187 - accuracy: 0.9969\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9988\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0133 - accuracy: 0.9985\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9989\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9993\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0072 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9989\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9971\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.1497e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.9436e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.1784e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 0.9997\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0282 - accuracy: 0.9908\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.8499e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 5.6357e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2634 - accuracy: 0.9511\n","Model: \"sequential_283\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_282 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_564 (Dense)           (None, 62)                48670     \n","                                                                 \n"," dense_565 (Dense)           (None, 10)                630       \n","                                                                 \n","=================================================================\n","Total params: 49,300\n","Trainable params: 49,300\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  61  ===> The model has  62 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.5807 - accuracy: 0.8444\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2827 - accuracy: 0.9211\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2224 - accuracy: 0.9367\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1846 - accuracy: 0.9462\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1528 - accuracy: 0.9582\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1310 - accuracy: 0.9645\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1117 - accuracy: 0.9703\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9735\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0836 - accuracy: 0.9775\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0705 - accuracy: 0.9817\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0619 - accuracy: 0.9836\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0537 - accuracy: 0.9868\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9895\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0406 - accuracy: 0.9906\n","Epoch 5/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0338 - accuracy: 0.9928\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9939\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9961\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0199 - accuracy: 0.9970\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9975\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9984\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9989\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9995\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9994\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9997\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0381 - accuracy: 0.9864\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.1375e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2656 - accuracy: 0.9488\n","Model: \"sequential_284\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_283 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_566 (Dense)           (None, 62)                48670     \n","                                                                 \n"," dense_567 (Dense)           (None, 10)                630       \n","                                                                 \n","=================================================================\n","Total params: 49,300\n","Trainable params: 49,300\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  62  ===> The model has  63 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5918 - accuracy: 0.8418\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2839 - accuracy: 0.9190\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9386\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1829 - accuracy: 0.9490\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1547 - accuracy: 0.9571\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1303 - accuracy: 0.9631\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1102 - accuracy: 0.9695\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9739\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0833 - accuracy: 0.9779\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0717 - accuracy: 0.9809\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9853\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9874\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0456 - accuracy: 0.9888\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9910\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9921\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0303 - accuracy: 0.9934\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9952\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0215 - accuracy: 0.9963\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9973\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0183 - accuracy: 0.9969\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9971\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9988\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9992\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9994\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9991\n","Epoch 4/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9995\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 0.9997\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9951\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9995\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.5285e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.6046e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2556 - accuracy: 0.9498\n","Model: \"sequential_285\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_284 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_568 (Dense)           (None, 63)                49455     \n","                                                                 \n"," dense_569 (Dense)           (None, 10)                640       \n","                                                                 \n","=================================================================\n","Total params: 50,095\n","Trainable params: 50,095\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  62  ===> The model has  63 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6048 - accuracy: 0.8370\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2768 - accuracy: 0.9215\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2175 - accuracy: 0.9380\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1786 - accuracy: 0.9488\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1494 - accuracy: 0.9572\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1280 - accuracy: 0.9628\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1074 - accuracy: 0.9707\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0942 - accuracy: 0.9750\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0821 - accuracy: 0.9769\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0701 - accuracy: 0.9815\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9856\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0532 - accuracy: 0.9867\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9890\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9917\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9940\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0304 - accuracy: 0.9931\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9955\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9965\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9972\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9970\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9986\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9992\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9991\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0075 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9978\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9979\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.3495e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.2141e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.1074e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2484 - accuracy: 0.9503\n","Model: \"sequential_286\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_285 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_570 (Dense)           (None, 63)                49455     \n","                                                                 \n"," dense_571 (Dense)           (None, 10)                640       \n","                                                                 \n","=================================================================\n","Total params: 50,095\n","Trainable params: 50,095\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  63  ===> The model has  64 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6091 - accuracy: 0.8390\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2752 - accuracy: 0.9224\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2145 - accuracy: 0.9398\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1741 - accuracy: 0.9506\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1500 - accuracy: 0.9554\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1264 - accuracy: 0.9634\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1074 - accuracy: 0.9694\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0933 - accuracy: 0.9751\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0800 - accuracy: 0.9787\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0674 - accuracy: 0.9824\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9833\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9876\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9897\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0397 - accuracy: 0.9908\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9923\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9954\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0253 - accuracy: 0.9959\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0221 - accuracy: 0.9953\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9976\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9977\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9983\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9993\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9997\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9994\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9980\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0108 - accuracy: 0.9976\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.9542e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.2856e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.9373e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.2690e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2508 - accuracy: 0.9526\n","Model: \"sequential_287\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_286 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_572 (Dense)           (None, 64)                50240     \n","                                                                 \n"," dense_573 (Dense)           (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 50,890\n","Trainable params: 50,890\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  63  ===> The model has  64 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.6032 - accuracy: 0.8409\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2806 - accuracy: 0.9218\n","Epoch 3/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2243 - accuracy: 0.9365\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1822 - accuracy: 0.9480\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1538 - accuracy: 0.9564\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1313 - accuracy: 0.9641\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1101 - accuracy: 0.9703\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0928 - accuracy: 0.9752\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9792\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0691 - accuracy: 0.9825\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9868\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0509 - accuracy: 0.9883\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9899\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0361 - accuracy: 0.9927\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0321 - accuracy: 0.9939\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0263 - accuracy: 0.9959\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0224 - accuracy: 0.9967\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9973\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9988\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9979\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9981\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0113 - accuracy: 0.9987\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9997\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9951\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9972\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.4932e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.9520\n","Model: \"sequential_288\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_287 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_574 (Dense)           (None, 64)                50240     \n","                                                                 \n"," dense_575 (Dense)           (None, 10)                650       \n","                                                                 \n","=================================================================\n","Total params: 50,890\n","Trainable params: 50,890\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  64  ===> The model has  65 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.5866 - accuracy: 0.8447\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2705 - accuracy: 0.9242\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2070 - accuracy: 0.9398\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1688 - accuracy: 0.9517\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1391 - accuracy: 0.9604\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1168 - accuracy: 0.9685\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9733\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0816 - accuracy: 0.9797\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9819\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0594 - accuracy: 0.9850\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0510 - accuracy: 0.9883\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9903\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9923\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0312 - accuracy: 0.9940\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0259 - accuracy: 0.9954\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0206 - accuracy: 0.9968\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0188 - accuracy: 0.9973\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9980\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9991\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9997\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0091 - accuracy: 0.9991\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9998\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9947\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9995\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.8213e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.8718e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2294 - accuracy: 0.9543\n","Model: \"sequential_289\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_288 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_576 (Dense)           (None, 65)                51025     \n","                                                                 \n"," dense_577 (Dense)           (None, 10)                660       \n","                                                                 \n","=================================================================\n","Total params: 51,685\n","Trainable params: 51,685\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  64  ===> The model has  65 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6009 - accuracy: 0.8369\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2729 - accuracy: 0.9227\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2102 - accuracy: 0.9403\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9507\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1424 - accuracy: 0.9603\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1184 - accuracy: 0.9676\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1013 - accuracy: 0.9728\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0876 - accuracy: 0.9766\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0743 - accuracy: 0.9801\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0639 - accuracy: 0.9835\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9879\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9884\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0397 - accuracy: 0.9911\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9923\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9938\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9951\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0219 - accuracy: 0.9961\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9978\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9975\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0152 - accuracy: 0.9976\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9997\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9995\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0057 - accuracy: 0.9998\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9997\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9997\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9940\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9995\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.3552e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.5454e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.8208e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.7607e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2563 - accuracy: 0.9523\n","Model: \"sequential_290\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_289 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_578 (Dense)           (None, 65)                51025     \n","                                                                 \n"," dense_579 (Dense)           (None, 10)                660       \n","                                                                 \n","=================================================================\n","Total params: 51,685\n","Trainable params: 51,685\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  65  ===> The model has  66 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6030 - accuracy: 0.8402\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2863 - accuracy: 0.9206\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2222 - accuracy: 0.9372\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1804 - accuracy: 0.9486\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1491 - accuracy: 0.9580\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1272 - accuracy: 0.9640\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1066 - accuracy: 0.9702\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0922 - accuracy: 0.9736\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9799\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9822\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0560 - accuracy: 0.9856\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0484 - accuracy: 0.9891\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9904\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9930\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0299 - accuracy: 0.9942\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0250 - accuracy: 0.9960\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9964\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0184 - accuracy: 0.9976\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9982\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9989\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9990\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9983\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9994\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9964\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9947\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9993\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.6343e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.2804e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.5091e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.9528\n","Model: \"sequential_291\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_290 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_580 (Dense)           (None, 66)                51810     \n","                                                                 \n"," dense_581 (Dense)           (None, 10)                670       \n","                                                                 \n","=================================================================\n","Total params: 52,480\n","Trainable params: 52,480\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  65  ===> The model has  66 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5961 - accuracy: 0.8409\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.9249\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2109 - accuracy: 0.9426\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1676 - accuracy: 0.9539\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1404 - accuracy: 0.9601\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1179 - accuracy: 0.9668\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0984 - accuracy: 0.9736\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0832 - accuracy: 0.9796\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0708 - accuracy: 0.9814\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0609 - accuracy: 0.9854\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0514 - accuracy: 0.9878\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0459 - accuracy: 0.9890\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0392 - accuracy: 0.9915\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0306 - accuracy: 0.9950\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9948\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9952\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0196 - accuracy: 0.9973\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9981\n","Epoch 4/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9973\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9994\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0105 - accuracy: 0.9992\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9990\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9993\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9977\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9979\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.0537e-04 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.3568e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.4432e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.9257e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.1251e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2302 - accuracy: 0.9528\n","Model: \"sequential_292\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_291 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_582 (Dense)           (None, 66)                51810     \n","                                                                 \n"," dense_583 (Dense)           (None, 10)                670       \n","                                                                 \n","=================================================================\n","Total params: 52,480\n","Trainable params: 52,480\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  66  ===> The model has  67 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6064 - accuracy: 0.8439\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.9225\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2183 - accuracy: 0.9382\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1785 - accuracy: 0.9497\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1477 - accuracy: 0.9598\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1242 - accuracy: 0.9657\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1063 - accuracy: 0.9718\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0913 - accuracy: 0.9760\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0802 - accuracy: 0.9797\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0673 - accuracy: 0.9839\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0610 - accuracy: 0.9849\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9878\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9909\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0367 - accuracy: 0.9928\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0305 - accuracy: 0.9935\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0273 - accuracy: 0.9951\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0223 - accuracy: 0.9958\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0190 - accuracy: 0.9970\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9976\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0131 - accuracy: 0.9984\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9988\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9992\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9992\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0065 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9993\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9911\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9993\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.8314e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.8039e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 7.1513e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2563 - accuracy: 0.9496\n","Model: \"sequential_293\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_292 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_584 (Dense)           (None, 67)                52595     \n","                                                                 \n"," dense_585 (Dense)           (None, 10)                680       \n","                                                                 \n","=================================================================\n","Total params: 53,275\n","Trainable params: 53,275\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  66  ===> The model has  67 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5989 - accuracy: 0.8379\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2747 - accuracy: 0.9254\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2120 - accuracy: 0.9408\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1693 - accuracy: 0.9518\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1393 - accuracy: 0.9599\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1137 - accuracy: 0.9697\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0953 - accuracy: 0.9754\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0819 - accuracy: 0.9773\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0683 - accuracy: 0.9822\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9863\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9898\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0418 - accuracy: 0.9924\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9929\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9930\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9961\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9973\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9970\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0171 - accuracy: 0.9975\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0120 - accuracy: 0.9991\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9993\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9995\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9970\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0136 - accuracy: 0.9964\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9993\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.8746e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2286 - accuracy: 0.9532\n","Model: \"sequential_294\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_293 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_586 (Dense)           (None, 67)                52595     \n","                                                                 \n"," dense_587 (Dense)           (None, 10)                680       \n","                                                                 \n","=================================================================\n","Total params: 53,275\n","Trainable params: 53,275\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  67  ===> The model has  68 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6078 - accuracy: 0.8383\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2817 - accuracy: 0.9200\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2235 - accuracy: 0.9367\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1813 - accuracy: 0.9501\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1494 - accuracy: 0.9579\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1257 - accuracy: 0.9657\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1074 - accuracy: 0.9702\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0912 - accuracy: 0.9758\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0763 - accuracy: 0.9802\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0659 - accuracy: 0.9835\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0558 - accuracy: 0.9866\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9894\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9911\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0345 - accuracy: 0.9930\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0293 - accuracy: 0.9937\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0242 - accuracy: 0.9955\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0211 - accuracy: 0.9968\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9970\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9977\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9991\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9989\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9992\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9997\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9993\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9998\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9936\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9983\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.0412e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.5856e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.6794e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2358 - accuracy: 0.9563\n","Model: \"sequential_295\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_294 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_588 (Dense)           (None, 68)                53380     \n","                                                                 \n"," dense_589 (Dense)           (None, 10)                690       \n","                                                                 \n","=================================================================\n","Total params: 54,070\n","Trainable params: 54,070\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  67  ===> The model has  68 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6117 - accuracy: 0.8358\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2795 - accuracy: 0.9256\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2190 - accuracy: 0.9381\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1786 - accuracy: 0.9500\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1483 - accuracy: 0.9585\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.9665\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1053 - accuracy: 0.9709\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0880 - accuracy: 0.9767\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0752 - accuracy: 0.9800\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0656 - accuracy: 0.9830\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0562 - accuracy: 0.9856\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0467 - accuracy: 0.9898\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9904\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0320 - accuracy: 0.9940\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0300 - accuracy: 0.9942\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9958\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9972\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0171 - accuracy: 0.9976\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9982\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9997\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9997\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0066 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9996\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9940\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.2510e-04 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.9586e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.5992e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.0512e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 5.7142e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.9527\n","Model: \"sequential_296\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_295 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_590 (Dense)           (None, 68)                53380     \n","                                                                 \n"," dense_591 (Dense)           (None, 10)                690       \n","                                                                 \n","=================================================================\n","Total params: 54,070\n","Trainable params: 54,070\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  68  ===> The model has  69 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.6040 - accuracy: 0.8376\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2780 - accuracy: 0.9243\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2138 - accuracy: 0.9415\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9511\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1468 - accuracy: 0.9597\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.9676\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9729\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9768\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0729 - accuracy: 0.9803\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0604 - accuracy: 0.9853\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0504 - accuracy: 0.9879\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0446 - accuracy: 0.9900\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0363 - accuracy: 0.9923\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9938\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy: 0.9966\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9981\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0181 - accuracy: 0.9980\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0150 - accuracy: 0.9983\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9987\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9990\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9992\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0061 - accuracy: 0.9996\n","Epoch 5/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9957\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0145 - accuracy: 0.9961\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9996\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.9913e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.2262e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2108 - accuracy: 0.9534\n","Model: \"sequential_297\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_296 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_592 (Dense)           (None, 69)                54165     \n","                                                                 \n"," dense_593 (Dense)           (None, 10)                700       \n","                                                                 \n","=================================================================\n","Total params: 54,865\n","Trainable params: 54,865\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  68  ===> The model has  69 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5888 - accuracy: 0.8431\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2773 - accuracy: 0.9220\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2185 - accuracy: 0.9382\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9498\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9594\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1237 - accuracy: 0.9657\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1020 - accuracy: 0.9726\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0886 - accuracy: 0.9761\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0727 - accuracy: 0.9810\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0627 - accuracy: 0.9848\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0521 - accuracy: 0.9876\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0437 - accuracy: 0.9907\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9921\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0309 - accuracy: 0.9941\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0267 - accuracy: 0.9958\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0212 - accuracy: 0.9973\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0188 - accuracy: 0.9979\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0161 - accuracy: 0.9974\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9991\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9991\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9987\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0050 - accuracy: 0.9992\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0163 - accuracy: 0.9957\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.3557e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2315 - accuracy: 0.9502\n","Model: \"sequential_298\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_297 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_594 (Dense)           (None, 69)                54165     \n","                                                                 \n"," dense_595 (Dense)           (None, 10)                700       \n","                                                                 \n","=================================================================\n","Total params: 54,865\n","Trainable params: 54,865\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  69  ===> The model has  70 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5898 - accuracy: 0.8424\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2673 - accuracy: 0.9264\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2086 - accuracy: 0.9415\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1678 - accuracy: 0.9530\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1384 - accuracy: 0.9618\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1177 - accuracy: 0.9671\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0969 - accuracy: 0.9741\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9775\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9806\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9849\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0526 - accuracy: 0.9879\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9908\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0364 - accuracy: 0.9928\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0328 - accuracy: 0.9931\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0274 - accuracy: 0.9953\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9973\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9977\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0167 - accuracy: 0.9973\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0124 - accuracy: 0.9988\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9987\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9993\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9995\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0074 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9984\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9997\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 0.9999\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9932\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9990\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.2112e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.7201e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.6511e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.0179e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2362 - accuracy: 0.9522\n","Model: \"sequential_299\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_298 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_596 (Dense)           (None, 70)                54950     \n","                                                                 \n"," dense_597 (Dense)           (None, 10)                710       \n","                                                                 \n","=================================================================\n","Total params: 55,660\n","Trainable params: 55,660\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  69  ===> The model has  70 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5767 - accuracy: 0.8404\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2682 - accuracy: 0.9249\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2095 - accuracy: 0.9426\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1721 - accuracy: 0.9504\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.9572\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1207 - accuracy: 0.9655\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1017 - accuracy: 0.9728\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0856 - accuracy: 0.9776\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0738 - accuracy: 0.9796\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0631 - accuracy: 0.9845\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9869\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9901\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9917\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9922\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9951\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9955\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0195 - accuracy: 0.9973\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9970\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9985\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9988\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9990\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9992\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0037 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0246 - accuracy: 0.9928\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9977\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0032 - accuracy: 0.9998\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.4122e-04 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.5783e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.9480e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.0408e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.3914e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2441 - accuracy: 0.9526\n","Model: \"sequential_300\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_299 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_598 (Dense)           (None, 70)                54950     \n","                                                                 \n"," dense_599 (Dense)           (None, 10)                710       \n","                                                                 \n","=================================================================\n","Total params: 55,660\n","Trainable params: 55,660\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  70  ===> The model has  71 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5767 - accuracy: 0.8414\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2630 - accuracy: 0.9265\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2052 - accuracy: 0.9422\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1643 - accuracy: 0.9541\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1334 - accuracy: 0.9625\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1104 - accuracy: 0.9694\n","Epoch 2/5\n","313/313 [==============================] - 2s 6ms/step - loss: 0.0924 - accuracy: 0.9756\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0794 - accuracy: 0.9794\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0659 - accuracy: 0.9836\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0567 - accuracy: 0.9866\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0483 - accuracy: 0.9880\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9915\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9935\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9946\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0241 - accuracy: 0.9958\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9970\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9979\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9991\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0099 - accuracy: 0.9995\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9998\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9990\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0083 - accuracy: 0.9992\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9989\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0043 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9978\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0217 - accuracy: 0.9926\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9998\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.9775e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2242 - accuracy: 0.9546\n","Model: \"sequential_301\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_300 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_600 (Dense)           (None, 71)                55735     \n","                                                                 \n"," dense_601 (Dense)           (None, 10)                720       \n","                                                                 \n","=================================================================\n","Total params: 56,455\n","Trainable params: 56,455\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  70  ===> The model has  71 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.6026 - accuracy: 0.8400\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2754 - accuracy: 0.9245\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2151 - accuracy: 0.9392\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1758 - accuracy: 0.9505\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1470 - accuracy: 0.9596\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1226 - accuracy: 0.9665\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9729\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0906 - accuracy: 0.9760\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0753 - accuracy: 0.9806\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0644 - accuracy: 0.9842\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0557 - accuracy: 0.9854\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9894\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0385 - accuracy: 0.9915\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0327 - accuracy: 0.9932\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9953\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0222 - accuracy: 0.9970\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0189 - accuracy: 0.9978\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9976\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9984\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9995\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0098 - accuracy: 0.9994\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0096 - accuracy: 0.9988\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0043 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0258 - accuracy: 0.9922\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9990\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 0.9997\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.7765e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2263 - accuracy: 0.9527\n","Model: \"sequential_302\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_301 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_602 (Dense)           (None, 71)                55735     \n","                                                                 \n"," dense_603 (Dense)           (None, 10)                720       \n","                                                                 \n","=================================================================\n","Total params: 56,455\n","Trainable params: 56,455\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  71  ===> The model has  72 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5942 - accuracy: 0.8384\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2775 - accuracy: 0.9229\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2149 - accuracy: 0.9396\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1743 - accuracy: 0.9507\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1427 - accuracy: 0.9600\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1199 - accuracy: 0.9673\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0999 - accuracy: 0.9741\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0848 - accuracy: 0.9772\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0715 - accuracy: 0.9815\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0632 - accuracy: 0.9839\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9885\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9901\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0367 - accuracy: 0.9919\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0321 - accuracy: 0.9931\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0264 - accuracy: 0.9952\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0226 - accuracy: 0.9965\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9973\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9981\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9988\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9984\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9993\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0046 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0036 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0029 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9942\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0081 - accuracy: 0.9982\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.5417e-04 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.5314e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.8077e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.1097e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 5.6341e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2385 - accuracy: 0.9532\n","Model: \"sequential_303\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_302 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_604 (Dense)           (None, 72)                56520     \n","                                                                 \n"," dense_605 (Dense)           (None, 10)                730       \n","                                                                 \n","=================================================================\n","Total params: 57,250\n","Trainable params: 57,250\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  71  ===> The model has  72 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5847 - accuracy: 0.8421\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2676 - accuracy: 0.9241\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2045 - accuracy: 0.9430\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1632 - accuracy: 0.9540\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1369 - accuracy: 0.9610\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1127 - accuracy: 0.9687\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0936 - accuracy: 0.9741\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0807 - accuracy: 0.9793\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0678 - accuracy: 0.9823\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0577 - accuracy: 0.9861\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0492 - accuracy: 0.9885\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0417 - accuracy: 0.9915\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9928\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0288 - accuracy: 0.9950\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0256 - accuracy: 0.9949\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0218 - accuracy: 0.9965\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0164 - accuracy: 0.9985\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9978\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9983\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0097 - accuracy: 0.9994\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0085 - accuracy: 0.9994\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9977\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9975\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0026 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.7644e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.6561e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2399 - accuracy: 0.9537\n","Model: \"sequential_304\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_303 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_606 (Dense)           (None, 72)                56520     \n","                                                                 \n"," dense_607 (Dense)           (None, 10)                730       \n","                                                                 \n","=================================================================\n","Total params: 57,250\n","Trainable params: 57,250\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  72  ===> The model has  73 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5664 - accuracy: 0.8481\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2811 - accuracy: 0.9210\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2180 - accuracy: 0.9375\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9521\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.9583\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.9645\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1007 - accuracy: 0.9730\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0860 - accuracy: 0.9772\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0736 - accuracy: 0.9807\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9847\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0527 - accuracy: 0.9875\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0443 - accuracy: 0.9899\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0387 - accuracy: 0.9905\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9939\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9950\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0230 - accuracy: 0.9959\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0176 - accuracy: 0.9977\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9988\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9978\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9993\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0076 - accuracy: 0.9997\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0044 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0039 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0038 - accuracy: 0.9997\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9919\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9984\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.0149e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2236 - accuracy: 0.9539\n","Model: \"sequential_305\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_304 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_608 (Dense)           (None, 73)                57305     \n","                                                                 \n"," dense_609 (Dense)           (None, 10)                740       \n","                                                                 \n","=================================================================\n","Total params: 58,045\n","Trainable params: 58,045\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  72  ===> The model has  73 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5963 - accuracy: 0.8422\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2615 - accuracy: 0.9277\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.9420\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1610 - accuracy: 0.9536\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1305 - accuracy: 0.9640\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1078 - accuracy: 0.9701\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0888 - accuracy: 0.9754\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9809\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0623 - accuracy: 0.9836\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0520 - accuracy: 0.9878\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9896\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0367 - accuracy: 0.9922\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9944\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0246 - accuracy: 0.9956\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0209 - accuracy: 0.9972\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0177 - accuracy: 0.9977\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.9979\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0116 - accuracy: 0.9986\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0103 - accuracy: 0.9990\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9996\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9990\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0069 - accuracy: 0.9993\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0033 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0082 - accuracy: 0.9983\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0093 - accuracy: 0.9985\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.9426e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 8.9765e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.6890e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.1787e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2186 - accuracy: 0.9548\n","Model: \"sequential_306\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_305 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_610 (Dense)           (None, 73)                57305     \n","                                                                 \n"," dense_611 (Dense)           (None, 10)                740       \n","                                                                 \n","=================================================================\n","Total params: 58,045\n","Trainable params: 58,045\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  73  ===> The model has  74 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.5919 - accuracy: 0.8448\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2782 - accuracy: 0.9229\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2093 - accuracy: 0.9414\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9524\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1386 - accuracy: 0.9619\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9694\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0952 - accuracy: 0.9742\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9790\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9834\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0580 - accuracy: 0.9859\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0479 - accuracy: 0.9893\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0412 - accuracy: 0.9901\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9928\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9952\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0236 - accuracy: 0.9962\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9978\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0169 - accuracy: 0.9976\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9988\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0112 - accuracy: 0.9986\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0084 - accuracy: 0.9998\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0146 - accuracy: 0.9969\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9990\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9995\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 8.7813e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.7665e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2291 - accuracy: 0.9551\n","Model: \"sequential_307\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_306 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_612 (Dense)           (None, 74)                58090     \n","                                                                 \n"," dense_613 (Dense)           (None, 10)                750       \n","                                                                 \n","=================================================================\n","Total params: 58,840\n","Trainable params: 58,840\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  73  ===> The model has  74 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5704 - accuracy: 0.8458\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2805 - accuracy: 0.9209\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2190 - accuracy: 0.9396\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1751 - accuracy: 0.9502\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1421 - accuracy: 0.9594\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1171 - accuracy: 0.9685\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0991 - accuracy: 0.9741\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9803\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0692 - accuracy: 0.9817\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9863\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9891\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9901\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0332 - accuracy: 0.9933\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0289 - accuracy: 0.9942\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0231 - accuracy: 0.9960\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0208 - accuracy: 0.9967\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0157 - accuracy: 0.9979\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9989\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9993\n","Epoch 5/5\n","313/313 [==============================] - 2s 6ms/step - loss: 0.0084 - accuracy: 0.9997\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9998\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0047 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0052 - accuracy: 0.9995\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9995\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 8.5518e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.6346e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.4988e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2267 - accuracy: 0.9550\n","Model: \"sequential_308\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_307 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_614 (Dense)           (None, 74)                58090     \n","                                                                 \n"," dense_615 (Dense)           (None, 10)                750       \n","                                                                 \n","=================================================================\n","Total params: 58,840\n","Trainable params: 58,840\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  74  ===> The model has  75 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5685 - accuracy: 0.8489\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2728 - accuracy: 0.9243\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2145 - accuracy: 0.9383\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1776 - accuracy: 0.9494\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1475 - accuracy: 0.9596\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1245 - accuracy: 0.9657\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1079 - accuracy: 0.9695\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0917 - accuracy: 0.9759\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0788 - accuracy: 0.9778\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0671 - accuracy: 0.9825\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9860\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0489 - accuracy: 0.9884\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9909\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0380 - accuracy: 0.9915\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0308 - accuracy: 0.9941\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9949\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9967\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9969\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9971\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9985\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0131 - accuracy: 0.9988\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0101 - accuracy: 0.9989\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9997\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9992\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0100 - accuracy: 0.9987\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9993\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0041 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9987\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9957\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 0.9995\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 8.9268e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 8.2327e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 7.8168e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.2671e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2574 - accuracy: 0.9520\n","Model: \"sequential_309\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_308 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_616 (Dense)           (None, 75)                58875     \n","                                                                 \n"," dense_617 (Dense)           (None, 10)                760       \n","                                                                 \n","=================================================================\n","Total params: 59,635\n","Trainable params: 59,635\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  74  ===> The model has  75 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5505 - accuracy: 0.8541\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2616 - accuracy: 0.9265\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2038 - accuracy: 0.9432\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1656 - accuracy: 0.9528\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1362 - accuracy: 0.9623\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1111 - accuracy: 0.9703\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0955 - accuracy: 0.9749\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0796 - accuracy: 0.9800\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0657 - accuracy: 0.9820\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0570 - accuracy: 0.9861\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0464 - accuracy: 0.9899\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9909\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0335 - accuracy: 0.9938\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9948\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9967\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0184 - accuracy: 0.9977\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 0.9982\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0127 - accuracy: 0.9987\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9990\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9998\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0056 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0055 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0023 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9961\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0135 - accuracy: 0.9959\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.0200e-04 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.2406e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 6.1246e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 5.4357e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 2s 5ms/step - loss: 4.8633e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2413 - accuracy: 0.9563\n","Model: \"sequential_310\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_309 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_618 (Dense)           (None, 75)                58875     \n","                                                                 \n"," dense_619 (Dense)           (None, 10)                760       \n","                                                                 \n","=================================================================\n","Total params: 59,635\n","Trainable params: 59,635\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  75  ===> The model has  76 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5830 - accuracy: 0.8444\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2759 - accuracy: 0.9223\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2164 - accuracy: 0.9390\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1736 - accuracy: 0.9533\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1424 - accuracy: 0.9601\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9677\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1002 - accuracy: 0.9723\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0851 - accuracy: 0.9764\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0699 - accuracy: 0.9816\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0603 - accuracy: 0.9856\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0503 - accuracy: 0.9883\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9898\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0348 - accuracy: 0.9929\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0298 - accuracy: 0.9942\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9957\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0191 - accuracy: 0.9972\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0155 - accuracy: 0.9987\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9990\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9991\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9993\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0044 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0039 - accuracy: 0.9999\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0056 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0160 - accuracy: 0.9962\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9987\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0024 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0017 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 2s 6ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 8.8519e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 7.9153e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2255 - accuracy: 0.9539\n","Model: \"sequential_311\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_310 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_620 (Dense)           (None, 76)                59660     \n","                                                                 \n"," dense_621 (Dense)           (None, 10)                770       \n","                                                                 \n","=================================================================\n","Total params: 60,430\n","Trainable params: 60,430\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  75  ===> The model has  76 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5797 - accuracy: 0.8428\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2834 - accuracy: 0.9214\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2190 - accuracy: 0.9378\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1791 - accuracy: 0.9466\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1495 - accuracy: 0.9575\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1256 - accuracy: 0.9645\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1038 - accuracy: 0.9711\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0866 - accuracy: 0.9776\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0752 - accuracy: 0.9793\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9845\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0512 - accuracy: 0.9877\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0438 - accuracy: 0.9905\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9918\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9935\n","Epoch 5/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0263 - accuracy: 0.9956\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0210 - accuracy: 0.9968\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0192 - accuracy: 0.9971\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0146 - accuracy: 0.9987\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0120 - accuracy: 0.9990\n","Epoch 5/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0092 - accuracy: 0.9995\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9971\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9999\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0057 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9971\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9984\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.8416e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2240 - accuracy: 0.9547\n","Model: \"sequential_312\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_311 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_622 (Dense)           (None, 76)                59660     \n","                                                                 \n"," dense_623 (Dense)           (None, 10)                770       \n","                                                                 \n","=================================================================\n","Total params: 60,430\n","Trainable params: 60,430\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  76  ===> The model has  77 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5785 - accuracy: 0.8464\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2712 - accuracy: 0.9263\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2085 - accuracy: 0.9425\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1684 - accuracy: 0.9509\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1370 - accuracy: 0.9604\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1130 - accuracy: 0.9695\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0951 - accuracy: 0.9735\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9787\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0688 - accuracy: 0.9833\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9854\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0492 - accuracy: 0.9883\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0411 - accuracy: 0.9910\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9933\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9946\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9957\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0200 - accuracy: 0.9959\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9981\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0137 - accuracy: 0.9981\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0128 - accuracy: 0.9986\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0115 - accuracy: 0.9983\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0114 - accuracy: 0.9991\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0072 - accuracy: 0.9994\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0058 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9997\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0030 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0028 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9993\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9930\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0075 - accuracy: 0.9979\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 8.8919e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2324 - accuracy: 0.9550\n","Model: \"sequential_313\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_312 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_624 (Dense)           (None, 77)                60445     \n","                                                                 \n"," dense_625 (Dense)           (None, 10)                780       \n","                                                                 \n","=================================================================\n","Total params: 61,225\n","Trainable params: 61,225\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  76  ===> The model has  77 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5717 - accuracy: 0.8448\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2667 - accuracy: 0.9252\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2039 - accuracy: 0.9434\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1652 - accuracy: 0.9532\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1334 - accuracy: 0.9618\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1135 - accuracy: 0.9697\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0917 - accuracy: 0.9762\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0766 - accuracy: 0.9816\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0641 - accuracy: 0.9851\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0552 - accuracy: 0.9857\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0481 - accuracy: 0.9883\n","Epoch 2/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0396 - accuracy: 0.9915\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0316 - accuracy: 0.9949\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9959\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9948\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0199 - accuracy: 0.9966\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 0.9974\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0119 - accuracy: 0.9991\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0126 - accuracy: 0.9986\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0092 - accuracy: 0.9996\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9992\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0070 - accuracy: 0.9992\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0045 - accuracy: 0.9998\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0041 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0021 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9987\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9933\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9965\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0019 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.7524e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2249 - accuracy: 0.9553\n","Model: \"sequential_314\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_313 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_626 (Dense)           (None, 77)                60445     \n","                                                                 \n"," dense_627 (Dense)           (None, 10)                780       \n","                                                                 \n","=================================================================\n","Total params: 61,225\n","Trainable params: 61,225\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  77  ===> The model has  78 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5533 - accuracy: 0.8525\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2560 - accuracy: 0.9282\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2000 - accuracy: 0.9464\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1610 - accuracy: 0.9540\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1323 - accuracy: 0.9618\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1110 - accuracy: 0.9687\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0913 - accuracy: 0.9760\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0792 - accuracy: 0.9796\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0690 - accuracy: 0.9813\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0572 - accuracy: 0.9858\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0478 - accuracy: 0.9888\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0419 - accuracy: 0.9900\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9934\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0291 - accuracy: 0.9936\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0269 - accuracy: 0.9945\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0218 - accuracy: 0.9958\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0168 - accuracy: 0.9978\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9985\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9992\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 2s 6ms/step - loss: 0.0079 - accuracy: 0.9996\n","Epoch 2/5\n","313/313 [==============================] - 2s 7ms/step - loss: 0.0061 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 2s 6ms/step - loss: 0.0066 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.9994\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0053 - accuracy: 0.9997\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0141 - accuracy: 0.9961\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9999\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.3824e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.2332e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2356 - accuracy: 0.9524\n","Model: \"sequential_315\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_314 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_628 (Dense)           (None, 78)                61230     \n","                                                                 \n"," dense_629 (Dense)           (None, 10)                790       \n","                                                                 \n","=================================================================\n","Total params: 62,020\n","Trainable params: 62,020\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  77  ===> The model has  78 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 4ms/step - loss: 0.5725 - accuracy: 0.8452\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2681 - accuracy: 0.9274\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2077 - accuracy: 0.9401\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1688 - accuracy: 0.9516\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1341 - accuracy: 0.9630\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9683\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9751\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0798 - accuracy: 0.9786\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9845\n","Epoch 5/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0569 - accuracy: 0.9855\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9899\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0386 - accuracy: 0.9923\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0334 - accuracy: 0.9931\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0281 - accuracy: 0.9947\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0233 - accuracy: 0.9965\n","Epoch 1/5\n","313/313 [==============================] - 2s 6ms/step - loss: 0.0187 - accuracy: 0.9973\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0159 - accuracy: 0.9981\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9984\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0107 - accuracy: 0.9988\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9994\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0073 - accuracy: 0.9995\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9996\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9974\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0082 - accuracy: 0.9988\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0025 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0018 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0014 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 9.1953e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.2289e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 6.9202e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 3ms/step - loss: 0.2376 - accuracy: 0.9529\n","Model: \"sequential_316\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_315 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_630 (Dense)           (None, 78)                61230     \n","                                                                 \n"," dense_631 (Dense)           (None, 10)                790       \n","                                                                 \n","=================================================================\n","Total params: 62,020\n","Trainable params: 62,020\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  78  ===> The model has  79 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.5859 - accuracy: 0.8409\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2720 - accuracy: 0.9218\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2050 - accuracy: 0.9416\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1627 - accuracy: 0.9542\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1338 - accuracy: 0.9628\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1106 - accuracy: 0.9678\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0915 - accuracy: 0.9735\n","Epoch 3/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0781 - accuracy: 0.9798\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0658 - accuracy: 0.9825\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0558 - accuracy: 0.9855\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0466 - accuracy: 0.9891\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9924\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9920\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0283 - accuracy: 0.9949\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0239 - accuracy: 0.9958\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0198 - accuracy: 0.9965\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0166 - accuracy: 0.9975\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9978\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0109 - accuracy: 0.9989\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0094 - accuracy: 0.9992\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0087 - accuracy: 0.9992\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0068 - accuracy: 0.9997\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0050 - accuracy: 0.9994\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9973\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0076 - accuracy: 0.9990\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0034 - accuracy: 0.9996\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0020 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0015 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.5509e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.1359e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.7462e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2313 - accuracy: 0.9536\n","Model: \"sequential_317\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_316 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_632 (Dense)           (None, 79)                62015     \n","                                                                 \n"," dense_633 (Dense)           (None, 10)                800       \n","                                                                 \n","=================================================================\n","Total params: 62,815\n","Trainable params: 62,815\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","I an currently in run  78  ===> The model has  79 neurons. \n","amount = 2\n","10000 150\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.5778 - accuracy: 0.8406\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.2657 - accuracy: 0.9256\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.2083 - accuracy: 0.9407\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.9510\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.1376 - accuracy: 0.9607\n","Epoch 1/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.1160 - accuracy: 0.9675\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0958 - accuracy: 0.9744\n","Epoch 3/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0801 - accuracy: 0.9787\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0665 - accuracy: 0.9834\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0564 - accuracy: 0.9862\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9897\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0402 - accuracy: 0.9919\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9931\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0287 - accuracy: 0.9938\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0245 - accuracy: 0.9955\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0184 - accuracy: 0.9980\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0165 - accuracy: 0.9978\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0117 - accuracy: 0.9990\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0110 - accuracy: 0.9985\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9994\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0069 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0058 - accuracy: 0.9998\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0059 - accuracy: 0.9998\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0033 - accuracy: 0.9999\n","Epoch 1/5\n","313/313 [==============================] - 2s 5ms/step - loss: 0.0032 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9984\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0142 - accuracy: 0.9959\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0063 - accuracy: 0.9990\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n","Epoch 1/5\n","313/313 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000\n","Epoch 2/5\n","313/313 [==============================] - 1s 4ms/step - loss: 9.9458e-04 - accuracy: 1.0000\n","Epoch 3/5\n","313/313 [==============================] - 1s 4ms/step - loss: 8.8680e-04 - accuracy: 1.0000\n","Epoch 4/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.9100e-04 - accuracy: 1.0000\n","Epoch 5/5\n","313/313 [==============================] - 1s 4ms/step - loss: 7.1300e-04 - accuracy: 1.0000\n","313/313 [==============================] - 1s 2ms/step - loss: 0.2228 - accuracy: 0.9545\n","Model: \"sequential_318\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten_317 (Flatten)       (None, 784)               0         \n","                                                                 \n"," dense_634 (Dense)           (None, 79)                62015     \n","                                                                 \n"," dense_635 (Dense)           (None, 10)                800       \n","                                                                 \n","=================================================================\n","Total params: 62,815\n","Trainable params: 62,815\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x1080 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["\n","from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n","from matplotlib import cm\n","\n","def plot_risk_with_data(amount):\n","  data = []\n","  for i in range(len(amount)):\n","    data_help = (trainModel(4,1,50,1,200,amount[i], 0))\n","    data.append(data_help)\n"," \n","  viridis = cm.get_cmap('viridis', 12)\n","  colors = [viridis(x) for x in np.linspace(0.4,0.9,len(data))]\n","\n","  fig, ax = plt.subplots(1)\n","  fig.set_size_inches(20,15)\n","  for i in range(len(data)):\n","    ax.plot(data[i][2],linewidth=2.0, color = colors[i], label = str(amount[i]) + \" Samples\") \n","    #ax.plot(data[i][0],linewidth=2.0, color = colors[i]) \n","\n","  ax.set_xlabel('Layersize')\n","  ax.set_ylabel('loss')  \n","  ax.legend(loc='upper right')\n","  plt.savefig(\"more_is_less\")\n","\n","\n","amount = [4000,15000]\n","plot_risk_with_data(amount)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K5ouVK_uCaHz"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"more_is_less_Bachelorarbeit.ipynb","provenance":[{"file_id":"15KsO4F_j6p9Zo9Gv4t0fW7Afp32HvZzh","timestamp":1647705517504}],"authorship_tag":"ABX9TyNifBUcBAlNymJqjPr4FVHA"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}