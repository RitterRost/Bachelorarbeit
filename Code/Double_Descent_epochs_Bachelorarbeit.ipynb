{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Double_Descent_epochs_Bachelorarbeit.ipynb","provenance":[{"file_id":"15KsO4F_j6p9Zo9Gv4t0fW7Afp32HvZzh","timestamp":1647182054327}],"collapsed_sections":[],"authorship_tag":"ABX9TyOJlVlPsFH4RPm65h0kxvP1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7ZmwTMWx9AcY"},"outputs":[],"source":["#imports \n","\n","%tensorflow_version 2.x\n","import tensorflow as tf \n","from tensorflow import keras \n","\n","#Help-liberies \n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":[""],"metadata":{"id":"IavwwvkdKA-m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#The function takes the train labels and the amount of noise we want to apply \n","#The return value is the train_labels with noise \n","import random\n","\n","def adding_noise(y_labels, percent):\n","  for y in y_labels:\n","    r = random.random()\n","    if r < percent:\n","      y = int(y + 1+ 9*random.random())%10\n","  return y_labels"],"metadata":{"id":"pwiYmWF29Kh2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Creating the Class Model, where modelscan be created, trained and observed\n"],"metadata":{"id":"0CR7pt0n-IKt"}},{"cell_type":"code","source":["\n","\n","class Model:\n","      model = keras.Sequential()\n","\n","      def __init__(self, layers, layersize):\n","\n","        self.layers = layers\n","        self.layersize = layersize\n","        #initializing the model\n","        self.model = keras.Sequential()\n","        self.model.add(keras.layers.Flatten(input_shape=(28,28)))#input layer\n","        for j in range(0, layers):\n","          self.model.add(keras.layers.Dense(layersize, activation=\"relu\")) #hidden layers\n","        self.model.add(keras.layers.Dense(10,activation='softmax')) #output layer\n","        #compile model\n","        self.model.compile(optimizer= 'adam',loss= 'sparse_categorical_crossentropy',metrics=['accuracy'])  \n","        self.model.count_params()\n","\n","      '''\n","      trains the model and returns a List of various data\n","      data[0] = the train loss after fitting the data \n","      data[1] = the train accuracy after fitting the data  \n","      data[2] = the test loss after evaluating the model \n","      data[3] = the test accuracy after evaluating the model  \n","      '''\n","\n","      def train(self,epoch,datasize,train_images,train_labels,test_images, test_labels):\n","        data = np.zeros(4)\n","        print(datasize,epoch)\n","\n","        #trainig the model until a certain accuracy is reached\n","        runs = 0\n","        train_loss = 100\n","        train_acc = 0\n","        e_per_run = 10\n","        while (train_loss > 0.001) and runs < epoch:\n","          history = self.model.fit(train_images[:datasize], train_labels[:datasize],epochs = e_per_run)\n","          train_loss_all, train_acc_all = history.history.values()\n","          train_loss = train_loss_all[e_per_run-1]\n","          train_acc = train_acc_all[e_per_run-1]\n","          runs = runs + e_per_run\n","\n","        test_loss, test_acc = self.model.evaluate(test_images, test_labels, verbose=1)\n","        data[0] = train_loss\n","        data[1] = train_acc\n","        data[2] = test_loss\n","        data[3] = test_acc\n","        print(self.model.summary())\n","        return data\n","\n","      def getParameter(self):\n","        return self.model.count_params()\n","\n"],"metadata":{"id":"6xq2wEh697S-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def trainModel(amount,min_layersize,max_layersize, layers, epochs, datasize, noise):\n","  a = max_layersize - min_layersize \n","  data = np.zeros((5,a))\n","\n","  #load dataset MNIST\n","  mnist = keras.datasets.mnist\n","  #spliting into testing and training\n","  (train_images, train_labels_without_noise), (test_images, test_labels) = mnist.load_data()\n","  #normalizing data\n","  train_images = train_images/255.0\n","  test_images = test_images/255.0\n","  #adding noise\n","  train_labels = adding_noise(train_labels_without_noise, noise)\n","\n","  \n","  '''\n","  data[0][i] = the train loss after fitting the data in iterration i (with i layers) \n","  data[1][i] = the train accuracy after fitting the data in iterration i (with i layers)  \n","  data[2][i] = the test loss after evaluating the model in iterration i (with i layers) \n","  data[3][i] = the test accuracy after evaluating the model in iterration i (with i layers) \n","  data[4][i] = the parameters of the model in iterration i (with i layers)\n","  '''\n","\n","  for i in range(0,max_layersize - min_layersize):\n","    data_help = [0,0,0,0,0]\n","    for j in range(0,amount):\n","      print(\"I an currently in run \",i, \" ===> The model has \", i+ min_layersize ,\"neurons. \")\n","      print(\"amount =\", amount) \n","      myModel = Model(layers,i + min_layersize)\n","      history = myModel.train(epochs, datasize,train_images,train_labels,test_images, test_labels)\n","      param   = myModel.getParameter()\n","      data_help[0] = data_help[0] + history[0] \n","      data_help[1] = data_help[1] + history[1]\n","      data_help[2] = data_help[2] + history[2]\n","      data_help[3] = data_help[3] + history[3]\n","      data_help[4] = data_help[4] + param\n","\n","    #maby filtering runs, that went wrong\n","    data[0][i] = data_help[0]/amount\n","    data[1][i] = data_help[1]/amount\n","    data[2][i] = data_help[2]/amount\n","    data[3][i] = data_help[3]/amount\n","    data[4][i] = data_help[4]\n","  return data "],"metadata":{"id":"nIA3dy4h-uOM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["in the next block, i want to creata a example curve of the double descent"],"metadata":{"id":"UTPtKBXn-i_U"}},{"cell_type":"code","source":[""],"metadata":{"id":"NN4ivVmq-ig-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n","from matplotlib import cm\n","\n","def plot_risk_with_epochs(epochs):\n","  data = [trainModel(5,1,80,1,n ,20000, 0) for n in epochs]\n","\n","  viridis = cm.get_cmap('viridis', 12)\n","  colors = [viridis(x) for x in np.linspace(0.4,0.9,len(data))]\n","\n","  fig, ax = plt.subplots(1)\n","  fig.set_size_inches(20,15)\n","  for i in range(len(data)):\n","    ax.plot(data[i][2],linewidth=2.0, color = colors[i], label = str(epochs[i]) + \" epochs\" ) \n","    #ax.plot(data[i][0],linewidth=2.0, color = colors[i]) \n","    \n","  ax.legend(loc='upper right')\n","  plt.savefig(str(epochs) + \"kurve_with_various_epochs.png\")\n","\n","\n","#effect of 50,100,200 epochs\n","epochs = [50,100,200]\n","plot_risk_with_epochs(epochs)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":372},"id":"p7S5NL0X8RQR","executionInfo":{"status":"error","timestamp":1647976163682,"user_tz":-60,"elapsed":11,"user":{"displayName":"Ritter Rost","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08820756572124446994"}},"outputId":"64aaa1df-bf32-4bab-cb05-d0033455ec12"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-4502908849f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#effect of 50,100,200 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mplot_risk_with_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-4502908849f5>\u001b[0m in \u001b[0;36mplot_risk_with_epochs\u001b[0;34m(epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_risk_with_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mviridis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-4502908849f5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_risk_with_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrainModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mviridis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'trainModel' is not defined"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"K5ouVK_uCaHz"},"execution_count":null,"outputs":[]}]}